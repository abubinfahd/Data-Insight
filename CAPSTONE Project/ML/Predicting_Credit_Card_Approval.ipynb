{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Credit Card Approval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Credit Card Approval\n",
        "Commercial banks receive a lot of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this notebook, we will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.<br>\n",
        "We'll use the Credit Card Approval dataset from the **UCI Machine Learning Repository**.\n",
        "\n"
      ],
      "metadata": {
        "id": "bta188qo3a7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "QDQNU7BH35GC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataet<br>\n",
        "First, loading and viewing the dataset. We find that since this data is confidential, the contributor of the dataset has anonymized the feature names.<br>\n",
        "The output may appear a bit confusing at its first sight, but let's try to figure out the most important features of a credit card application. The features of this dataset have been anonymized to protect the privacy, but [this blog ](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html)gives us a pretty good overview of the probable features. The probable features in a typical credit card application are Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income and finally the ApprovalStatus. This gives us a pretty good starting point, and we can map these features with respect to the columns in the output."
      ],
      "metadata": {
        "id": "4YuHj-Br4dIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"/content/cc_approvals.data\", header = None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "srqjWvEg4LAj",
        "outputId": "eefd8ba2-6310-44dd-d47f-9ba6fe0a6cb8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e02dc1d-4f39-460c-ab79-00415af92ad4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e02dc1d-4f39-460c-ab79-00415af92ad4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e02dc1d-4f39-460c-ab79-00415af92ad4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e02dc1d-4f39-460c-ab79-00415af92ad4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data overview\n",
        "As we can see from our first glance at the data, the dataset has a mixture of numerical and non-numerical features. This can be fixed with some preprocessing, but before we do that, let's learn about the dataset a bit more to see if there are other dataset issues that need to be fixed."
      ],
      "metadata": {
        "id": "wfbiqhUS49cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Dataset information\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Inspect missing value\n",
        "print(df.tail(20))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Columns\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmx83BKE5CRs",
        "outputId": "0f1da428-308c-438e-d2f8-7dd3b7739632"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               2           7          10             14\n",
            "count  690.000000  690.000000  690.00000     690.000000\n",
            "mean     4.758725    2.223406    2.40000    1017.385507\n",
            "std      4.978163    3.346513    4.86294    5210.102598\n",
            "min      0.000000    0.000000    0.00000       0.000000\n",
            "25%      1.000000    0.165000    0.00000       0.000000\n",
            "50%      2.750000    1.000000    0.00000       5.000000\n",
            "75%      7.207500    2.625000    3.00000     395.500000\n",
            "max     28.000000   28.500000   67.00000  100000.000000\n",
            "\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    object \n",
            " 1   1       690 non-null    object \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    object \n",
            " 4   4       690 non-null    object \n",
            " 5   5       690 non-null    object \n",
            " 6   6       690 non-null    object \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    object \n",
            " 9   9       690 non-null    object \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    object \n",
            " 12  12      690 non-null    object \n",
            " 13  13      690 non-null    object \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.4+ KB\n",
            "None\n",
            "\n",
            "\n",
            "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
            "670  b  47.17   5.835  u  g   w   v  5.500  f  f   0  f  g  00465  150  -\n",
            "671  b  25.83  12.835  u  g  cc   v  0.500  f  f   0  f  g  00000    2  -\n",
            "672  a  50.25   0.835  u  g  aa   v  0.500  f  f   0  t  g  00240  117  -\n",
            "673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
            "674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
            "675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
            "676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
            "677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
            "678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
            "679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
            "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
            "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
            "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
            "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
            "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
            "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
            "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
            "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
            "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
            "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n",
            "\n",
            "\n",
            "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Dataset<br>\n",
        "Also, features like DriversLicense and ZipCode are not as important as the other features in the dataset for predicting credit card approvals."
      ],
      "metadata": {
        "id": "hl2_Ucl25_Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Drop the features 11 and 13\n",
        "df = df.drop([11, 13], axis=1)\n",
        "\n",
        "# Spliting dataset\n",
        "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "ONBjwUZy7tCH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling missing value"
      ],
      "metadata": {
        "id": "uyLQSoi28B68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Replace the '?'s with NaN in the train and test sets\n",
        "df_train = df_train.replace('?', np.NaN)\n",
        "df_test = df_test.replace('?', np.NaN)"
      ],
      "metadata": {
        "id": "hT95df6k8FYE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are going to impute the missing values with a strategy called mean imputation."
      ],
      "metadata": {
        "id": "9gl9MBJi8XOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute the missing values with mean imputation\n",
        "df_train.fillna(df_train.mean(), inplace=True)\n",
        "df_test.fillna(df_train.mean(), inplace=True)\n",
        "\n",
        "# Count the number of NaNs in the datasets and print the counts to verify\n",
        "print(df_train.isnull().sum())\n",
        "print(df_test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaOr1Jpb8Rz8",
        "outputId": "78956081-ec1f-4283-ac8f-c5e0ce07b209"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     8\n",
            "1     5\n",
            "2     0\n",
            "3     6\n",
            "4     6\n",
            "5     7\n",
            "6     7\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "12    0\n",
            "14    0\n",
            "15    0\n",
            "dtype: int64\n",
            "0     4\n",
            "1     7\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     2\n",
            "6     2\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "12    0\n",
            "14    0\n",
            "15    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each column of df_train\n",
        "for col in df_train.columns:\n",
        "    # Check if the column is of object type\n",
        "    if df_train[col].dtypes == 'object':\n",
        "        # Impute with the most frequent value\n",
        "        df_train = df_train.fillna(df_train[col].value_counts().index[0])\n",
        "        df_test = df_test.fillna(df_train[col].value_counts().index[0])\n",
        "\n",
        "# Count the number of NaNs in the dataset and print the counts to verify\n",
        "print(df_train.isnull().sum())\n",
        "print(df_test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QRx8Je-88k3",
        "outputId": "952e0c62-23d1-4d97-cb7e-744bbced7404"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "12    0\n",
            "14    0\n",
            "15    0\n",
            "dtype: int64\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "12    0\n",
            "14    0\n",
            "15    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "T4Ekea_CaN2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will be converting all the non-numeric values into numeric ones. We do this because not only it results in a faster computation but also many machine learning models (like XGBoost) (and especially the ones developed using scikit-learn) require the data to be in a strictly numeric format. We will do this by using the get_dummies() method from pandas."
      ],
      "metadata": {
        "id": "v44TOMWlaLQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the categorical features in the train and test sets independently\n",
        "df_train = pd.get_dummies(df_train)\n",
        "df_test = pd.get_dummies(df_test)\n",
        "\n",
        "# Reindex the columns of the test set aligning with the train set\n",
        "df_test = df_test.reindex(columns=df_train.columns, fill_value=0)"
      ],
      "metadata": {
        "id": "9fa26vAgaJBo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we do a final preprocessing step of scaling before fit the model."
      ],
      "metadata": {
        "id": "YPTLKlyva8F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Segregate features and labels into separate variables\n",
        "X_train, y_train = df_train.iloc[:, :-1].values, df_train.iloc[:, [-1]].values\n",
        "X_test, y_test = df_test.iloc[:, :-1].values, df_test.iloc[:, [-1]].values\n",
        "\n",
        "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX_train = scaler.fit_transform(X_train)\n",
        "rescaledX_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "-WJIrSzbbJEE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a logistic regression model to the train set"
      ],
      "metadata": {
        "id": "XYZ0TXEJbdcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate a LogisticRegression classifier with default parameter values\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit logreg to the train set\n",
        "logreg.fit(rescaledX_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkVY-MH5bgY8",
        "outputId": "ba8fc44c-7ba0-42d4-8150-2de45492ddc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "9jgTdD-Pbrh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Use logreg to predict instances from the test set and store it\n",
        "y_pred = logreg.predict(rescaledX_test)\n",
        "\n",
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_zyUjzabttd",
        "outputId": "adbfe77c-b3ef-462a-83cd-66497f856143"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of logistic regression classifier:  1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[103,   0],\n",
              "       [  0, 125]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search for better Performance<br>\n",
        "Our model was pretty good! In fact it was able to yield an accuracy score of 100%."
      ],
      "metadata": {
        "id": "gDlEU4ilb1LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the grid of values for tol and max_iter\n",
        "tol = [0.01, 0.001 ,0.0001]\n",
        "max_iter = [100, 150, 200]\n",
        "\n",
        "# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\n",
        "param_grid = dict(tol=tol, max_iter=max_iter)"
      ],
      "metadata": {
        "id": "LUnTX94Tb5yG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have defined the grid of hyperparameter values and converted them into a single dictionary format which GridSearchCV() expects as one of its parameters. Now, we will begin the grid search to see which values perform best."
      ],
      "metadata": {
        "id": "hu5Vegg8da_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate GridSearchCV with the required parameters\n",
        "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
        "\n",
        "# Fit grid_model to the data\n",
        "grid_model_result = grid_model.fit(rescaledX_train, np.ravel(y_train))\n",
        "\n",
        "# Summarize results\n",
        "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
        "print(\"Best: %f using %s\" % (best_score, best_params))\n",
        "\n",
        "# Extract the best model and evaluate it on the test set\n",
        "best_model = grid_model_result.best_estimator_\n",
        "print(\"Accuracy of logistic regression classifier: \", best_model.score(rescaledX_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW2iYvgScJ-Q",
        "outputId": "35ca0372-0b0b-4072-d658-a300ce1c4159"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 1.000000 using {'max_iter': 100, 'tol': 0.01}\n",
            "Accuracy of logistic regression classifier:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best: 1.000000 using {'max_iter': 100, 'tol': 0.01}<br>\n",
        "Accuracy of logistic regression classifier:  1.0"
      ],
      "metadata": {
        "id": "QUMyptEtc5p7"
      }
    }
  ]
}